{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7lTx9HSezFLm"
   },
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle\n",
    "! touch ~/.kaggle/kaggle.json\n",
    "\n",
    "api_token = {\"username\": \"your-username\",\n",
    "             \"key\": \"your-key\"}\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "! kaggle datasets download -d giannisgeorgiou/fish-species\n",
    "\n",
    "! unzip fish-species.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tArjeqQbA7PA"
   },
   "outputs": [],
   "source": [
    "# Imports cell\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from shutil import copyfile, rmtree\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of all 20 classes\n",
    "INPUT_CLASSES_DIR = \"./Species/Training_Set/\"\n",
    "folders = glob(INPUT_CLASSES_DIR + '/*')\n",
    "n_classes = len(folders)\n",
    "\n",
    "# Number of samples per class for training (less than 1700)\n",
    "TRAIN_SAMPLE_SIZE = 200\n",
    "\n",
    "# Number of samples per class for testing (less than 300)\n",
    "TEST_SAMPLE_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all images to use for training and testing\n",
    "\n",
    "test_root = \"./test\"\n",
    "train_root = \"./train\"\n",
    "\n",
    "rmtree(train_root, ignore_errors=True)\n",
    "rmtree(test_root, ignore_errors=True)\n",
    "\n",
    "for dirname in folders:\n",
    "    current_subfolder = dirname.split(\"/\")[-1]\n",
    "    folder_sample = random.sample(glob(dirname + \"/*\"), TRAIN_SAMPLE_SIZE + TEST_SAMPLE_SIZE)\n",
    "    Path(f\"{test_root}/{current_subfolder}\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"{train_root}/{current_subfolder}\").mkdir(parents=True, exist_ok=True)\n",
    "    train_filenames = folder_sample[:TRAIN_SAMPLE_SIZE]\n",
    "    for f in train_filenames:\n",
    "        copyfile(f, f\"{train_root}/{current_subfolder}/{f.split('/')[-1]}\")\n",
    "    test_filenames = folder_sample[TRAIN_SAMPLE_SIZE:]\n",
    "    for f in test_filenames:\n",
    "        copyfile(f, f\"{test_root}/{current_subfolder}/{f.split('/')[-1]}\")\n",
    "\n",
    "train_files = glob(train_root + \"/*/*.jp*g\")\n",
    "test_files = glob(test_root + \"/*/*.jp*g\")\n",
    "\n",
    "print(len(train_files))\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.load_img(np.random.choice(train_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 network\n",
    "image_size = [200, 200]\n",
    "resnet = ResNet50(input_shape=image_size + [3], weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Make ResNet weights non trainable\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print summary\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain a neural network at the end\n",
    "x = Flatten()(resnet.output)\n",
    "prediction = Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Full model using the Functional API\n",
    "model = Model(inputs=resnet.input, outputs=prediction)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using appropriate loss and optimizer\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator objects for training and testing\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    train_root,\n",
    "    target_size=image_size,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"sparse\",\n",
    ")\n",
    "\n",
    "valid_generator = val_gen.flow_from_directory(\n",
    "    test_root,\n",
    "    target_size=image_size,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"sparse\",\n",
    ")\n",
    "\n",
    "test_gen = val_gen.flow_from_directory(\n",
    "    test_root, \n",
    "    target_size=image_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Translate labels into species\n",
    "\n",
    "labels = [None] * len(test_gen.class_indices)\n",
    "for k, v in test_gen.class_indices.items():\n",
    "    labels[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "epochs = 20\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fish.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
